# -*- coding: utf-8 -*-
"""preprocess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ia2rIBxMjbyBe0t_YZ689AIWD2SVOCrC
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""# Combining data

Here, we will combine all of our seven files into one
"""

import pandas as pd
import gc
import os

input_files = [
    '/content/gdrive/My Drive/ip_files/data/061_HEK293T_human_embryonic_kidney_csv.csv',
    '/content/gdrive/My Drive/ip_files/data/065_HEK293T_human_embryonic_kidney_csv.csv',
    '/content/gdrive/My Drive/ip_files/data/066_HEK293T_human_embryonic_kidney_csv.csv',
    '/content/gdrive/My Drive/ip_files/data/067_HEK293T_human_embryonic_kidney_csv.csv',
    '/content/gdrive/My Drive/ip_files/data/068_HEK293T_human_embryonic_kidney_csv.csv',
    '/content/gdrive/My Drive/ip_files/data/073_HEK293T-human_embryonic_kidney_matcsv.csv',
    '/content/gdrive/My Drive/ip_files/data/074_HEK293T-human_embryonic_kidney_csv.csv',
]

"""define function for transposing data

also, we will want to change column names, because of that transposing
"""

def transpose_and_set_column_names(df):
    """
    1. data will be transposed
    2. the first columns will be removed
    3. the same column will be placed for column names

    :param df: pandas.core.frame
    :return df: pandas.core.frame
    """

    # transpose
    df = df.T

    # set new column names and remove first column
    hg_names = df.iloc[0, :]
    df = df.iloc[1:, :]
    df.columns = hg_names

    return df

"""function for combining files"""

import gc

def combine_files(files):
    """
    create pandas data frame for every file
    transpose each one of them and change it's column names
    add class column
    combine them into one file

    :param files: list of paths
    :return: pandas.core.frame
    """

    # there are seven files, transpose and set col names for each
    df061 = pd.read_csv(files[0], index_col=False)
    df061 = transpose_and_set_column_names(df061)

    df065 = pd.read_csv(files[1], index_col=False)
    df065 = transpose_and_set_column_names(df065)

    df066 = pd.read_csv(files[2], index_col=False)
    df066 = transpose_and_set_column_names(df066)

    df067 = pd.read_csv(files[3], index_col=False)
    df067 = transpose_and_set_column_names(df067)

    df068 = pd.read_csv(files[4], index_col=False)
    df068 = transpose_and_set_column_names(df068)

    df073 = pd.read_csv(files[5], index_col=False)
    df073 = transpose_and_set_column_names(df073)

    df074 = pd.read_csv(files[6], index_col=False)
    df074 = transpose_and_set_column_names(df074)

    # also, add class column
    df061['class'] = 1
    df065['class'] = 2
    df066['class'] = 3
    df067['class'] = 4
    df068['class'] = 5
    df073['class'] = 6
    df074['class'] = 7

    gc.collect()
    
    # combine files
    df = pd.concat([df061, df065, df066, df067, df068, df073, df074], axis=0, ignore_index=True)

    return df

"""this will delete columns with zeros"""

def filter_zeros(df):
    """
    delete columns that contain nothing else but zeros
    :param df: pandas.core.frame
    :return: filtered pandas.core.frame
    """
    return df.loc[:, (df != 0).any(axis=0)]

"""we will just test things here"""

df = combine_files(input_files)
print(df.shape)

"""Now, we will delete columns that have zero for every value"""

df = filter_zeros(df)
print(df.shape)

"""save data frame into csv"""

df.to_csv('/content/gdrive/My Drive/ip_files/data/combined_data.csv', index=False)

"""# Outliers

Here we will filter outliers from our data. Local Outlier Factor will be used
"""

from sklearn.neighbors import LocalOutlierFactor

def remove_outliers(d_frame):
    """
    detect outliers with Local Outlier Factor
    delete them
    :param d_frame: pandas.core.frame
    :return: data frame without outliers
    """

    lof = LocalOutlierFactor(n_neighbors=5)
    lof.fit(d_frame)
    lof_factor = lof.negative_outlier_factor_

    outlier_factor = 1.8
    cluster_df = d_frame[lof_factor >= -outlier_factor]
    outlier_df = d_frame[lof_factor < -outlier_factor]

    return cluster_df, outlier_df

"""Read combined data file"""

import pandas as pd

df = pd.read_csv('/content/gdrive/My Drive/ip_files/data/combined_data.csv', index_col=False)
print(df.shape)

df, outliers = remove_outliers(df)
print(df.shape)
print(outliers.shape)

"""save data frame"""

df.to_csv('/content/gdrive/My Drive/ip_files/data/data_without_outliers.csv', index=False)
outliers.to_csv('/content/gdrive/My Drive/ip_files/data/outliers.csv', index=False)

"""## change class values

They had to be numeric because of Local outlier factor,  but now we will change them like this:
1 -> class1
2 -> class2
etc.
"""

import pandas as pd

df = pd.read_csv('/content/gdrive/My Drive/ip_files/data/data_without_outliers.csv', index_col=False)
outliers_df = pd.read_csv('/content/gdrive/My Drive/ip_files/data/outliers.csv', index_col=False)

df.loc[df['class'] == 1, 'class'] = 'class1'
df.loc[df['class'] == 2, 'class'] = 'class2'
df.loc[df['class'] == 3, 'class'] = 'class3'
df.loc[df['class'] == 4, 'class'] = 'class4'
df.loc[df['class'] == 5, 'class'] = 'class5'
df.loc[df['class'] == 6, 'class'] = 'class6'
df.loc[df['class'] == 7, 'class'] = 'class7'

outliers_df.loc[outliers_df['class'] == 1, 'class'] = 'class1'
outliers_df.loc[outliers_df['class'] == 2, 'class'] = 'class2'
outliers_df.loc[outliers_df['class'] == 3, 'class'] = 'class3'
outliers_df.loc[outliers_df['class'] == 4, 'class'] = 'class4'
outliers_df.loc[outliers_df['class'] == 5, 'class'] = 'class5'
outliers_df.loc[outliers_df['class'] == 6, 'class'] = 'class6'
outliers_df.loc[outliers_df['class'] == 7, 'class'] = 'class7'

df.to_csv('/content/gdrive/My Drive/ip_files/data/data_without_outliers.csv', index=False)
outliers_df.to_csv('/content/gdrive/My Drive/ip_files/data/outliers.csv', index=False)

"""## test data and outliers"""

import pandas as pd

df = pd.read_csv('/content/gdrive/My Drive/ip_files/data/data_without_outliers.csv', index_col=False)
print('data dataframe dimensions: {}'.format(df.shape))

classes = df['class']

from collections import Counter

print('data classes count:')
print(sorted(Counter(classes).items()))

import pandas as pd

outliers_df = pd.read_csv('/content/gdrive/My Drive/ip_files/data/outliers.csv', index_col=False)
print('outliers data frame dimensions: {}'.format(outliers_df.shape))

outliers_classes = outliers_df['class']

from collections import Counter

print('outliers classes count:')
print(sorted(Counter(outliers_classes).items()))

"""# Data sampling

Here we will resample instances of the classes
"""

import pandas as pd

df = pd.read_csv('/content/gdrive/My Drive/ip_files/data/data_without_outliers.csv', index_col=False)
print(df.shape)

from sklearn.utils import resample
from sklearn.model_selection import train_test_split

import gc

X = df.loc[:, df.columns != 'class']
y = df['class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=27)

del df
gc.collect()

X = pd.concat([X_train, y_train], axis=1)

gc.collect()

class2 = X.loc[X['class'] == 'class2']
rest_of_the_data = X.loc[X['class'] != 'class2']

del X
gc.collect()

# class2 = X[X.class == 'class2']
# rest_of_the_data = X[X.class != 'class2']

class2_upsampled = resample(class2, random_state=27, n_samples=150, replace=True)
upsampled = pd.concat([rest_of_the_data, class2_upsampled])

classes = upsampled['class']

gc.collect()

from collections import Counter

print('classes count:')
print(sorted(Counter(classes).items()))

# from imblearn.over_sampling import SMOTE
# from sklearn.model_selection import train_test_split

# # Separate input features and target
# X = df.loc[:, df.columns != 'class']
# y = df['class']

# # setting up testing and training sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)

# sm = SMOTE(random_state=27, ratio=0.5)
# X_train, y_train = sm.fit_sample(X_train, y_train)

""".........................."""

# from sklearn.utils import resample

# def resample_data(data_frame, class_for_resampling, number_of_samples):
#     """
#     create new instances of the selected class based
#     on the existing instances of that class

#     :param data_frame: rows of this data frame will be resampled
#     :param class_for_resampling: target class
#     :param number_of_samples: number of new class instances
#     :return: new, resampled data frame of the targeted class
#     """

#     data_frame_sampled = data_frame.loc[data_frame['class'] == class_for_resampling]
#     data_frame_sampled = data_frame_sampled.loc[:, data_frame_sampled.columns != 'class']

#     data_frame_sampled = resample(data_frame_sampled, n_samples=number_of_samples, random_state=0)
#     data_frame_sampled['class'] = class_for_resampling

#     # delete previous instances of target class from data frame
#     data_frame = data_frame.loc[data_frame['class'] != 'class2']

#     # add new ones instead
#     data_frame = pd.concat([data_frame, data_frame_sampled], axis=0, ignore_index=True)

#     return data_frame

"""number of instances of the class2 is low, so we will increase it"""

# new_df = resample_data(df, 'class2', 150)
# print(new_df.shape)

# new_df.to_csv('/content/gdrive/My Drive/ip_files/data/data_resampled.csv', index=False)

"""# train test split sa random state fiksnim i onda si OK!"""